{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesPath = os.listdir('bbox')\n",
    "imagesPath.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imList = np.zeros((0, 100, 100, 3))\n",
    "y_label = []\n",
    "for file in imagesPath:\n",
    "    im = cv2.imread('bbox/' + file)\n",
    "    im = cv2.resize(im, (100,100))\n",
    "    imList = np.insert(imList, 0, values=np.array([im]), axis=0)\n",
    "    y_label.append(0)\n",
    "    \n",
    "    im = cv2.flip(im,1)\n",
    "    imList = np.insert(imList, 0, values=np.array([im]), axis=0)\n",
    "    y_label.append(1)\n",
    "y_label = np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (488, 100, 100, 3)\n",
      "488 train samples\n",
      "488 test samples\n",
      "Train on 488 samples, validate on 488 samples\n",
      "Epoch 1/12\n",
      "488/488 [==============================] - 10s 21ms/step - loss: 3.9821 - acc: 0.5492 - val_loss: 0.6709 - val_acc: 0.5000\n",
      "Epoch 2/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.5844 - acc: 0.7418 - val_loss: 0.3548 - val_acc: 0.9713\n",
      "Epoch 3/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.8280 - acc: 0.8053 - val_loss: 0.2405 - val_acc: 0.9754\n",
      "Epoch 4/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.7599 - acc: 0.6148 - val_loss: 0.5652 - val_acc: 0.8770\n",
      "Epoch 5/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.3285 - acc: 0.9303 - val_loss: 0.3827 - val_acc: 0.7418\n",
      "Epoch 6/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.2653 - acc: 0.9160 - val_loss: 0.1196 - val_acc: 0.9918\n",
      "Epoch 7/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0755 - acc: 0.9877 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 8/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0245 - acc: 0.9980 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 9/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0159 - acc: 0.9980 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 10/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 11/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 12/12\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0116 - acc: 0.9980 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Test score: 0.006349787627514757\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "np.random.seed(1337)  # for reproducibility  \n",
    "from keras.datasets import mnist  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten  \n",
    "from keras.layers import Convolution2D, MaxPooling2D  \n",
    "from keras.utils import np_utils  \n",
    "from keras import backend as K  \n",
    "  \n",
    "# 全局变量  \n",
    "batch_size = 128  \n",
    "nb_classes = 2\n",
    "epochs = 12\n",
    "# input image dimensions  \n",
    "img_rows, img_cols = 100, 100\n",
    "# number of convolutional filters to use  \n",
    "nb_filters = 32  \n",
    "# size of pooling area for max pooling  \n",
    "pool_size = (2, 2)  \n",
    "# convolution kernel size  \n",
    "kernel_size = (3, 3)  \n",
    "  \n",
    "X_train = imList\n",
    "X_test = imList\n",
    "y_train = y_label\n",
    "y_test = y_label\n",
    "input_shape = (100,100,3)\n",
    "\n",
    "X_train = X_train.astype('float32')  \n",
    "X_test = X_test.astype('float32')  \n",
    "X_train /= 255  \n",
    "X_test /= 255  \n",
    "X_train = X_train.astype('float32') \n",
    "print('X_train shape:', X_train.shape)  \n",
    "print(X_train.shape[0], 'train samples')  \n",
    "print(X_test.shape[0], 'test samples')  \n",
    "  \n",
    "# 转换为one_hot类型  \n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)  \n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)  \n",
    "  \n",
    "#构建模型  \n",
    "model = Sequential()  \n",
    "\"\"\" \n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], \n",
    "                        border_mode='same', \n",
    "                        input_shape=input_shape)) \n",
    "\"\"\"  \n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1]),  \n",
    "                        padding='same',  \n",
    "                        input_shape=input_shape)) # 卷积层1  \n",
    "model.add(Activation('relu')) #激活层  \n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1]))) #卷积层2  \n",
    "model.add(Activation('relu')) #激活层  \n",
    "model.add(MaxPooling2D(pool_size=pool_size)) #池化层  \n",
    "model.add(Dropout(0.25)) #神经元随机失活  \n",
    "model.add(Flatten()) #拉成一维数据  \n",
    "model.add(Dense(128)) #全连接层1  \n",
    "model.add(Activation('relu')) #激活层  \n",
    "model.add(Dropout(0.5)) #随机失活  \n",
    "model.add(Dense(nb_classes)) #全连接层2  \n",
    "model.add(Activation('softmax')) #Softmax评分  \n",
    "  \n",
    "#编译模型  \n",
    "model.compile(loss='categorical_crossentropy',  \n",
    "              optimizer='adadelta',  \n",
    "              metrics=['accuracy'])  \n",
    "#训练模型  \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,  \n",
    "          verbose=1, validation_data=(X_test, Y_test))  \n",
    "#评估模型  \n",
    "score = model.evaluate(X_test, Y_test, verbose=0)  \n",
    "print('Test score:', score[0])  \n",
    "print('Test accuracy:', score[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "model.save_weights('weights.h5')\n",
    "import json\n",
    "with open(\"model.json\",'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
